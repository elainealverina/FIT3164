{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Main Program file for Cancer Predictive Model (Jupyter Notebook Version)\n",
    "## By: Group CL_04"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os, random, shutil\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from torchvision import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dividing Dataset (70% training, 30% testing)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def img_train_test_split(root_dir, classes_dir, test_ratio):\n",
    "    '''\n",
    "    This function splits a folder with subfolders into train and test datasets\n",
    "    :param root_dir: a string corresponding to the file path of the folder of subfolders of images\n",
    "    :param classes_dir: a list of strings of subfolder names\n",
    "    :param test_ratio: a float of the ratio of test dataset to train dataset\n",
    "    :return: None\n",
    "    '''\n",
    "\n",
    "    for cls in classes_dir:\n",
    "        # create a new train and test directory for cls\n",
    "        os.makedirs(root_dir + 'train/' + cls)\n",
    "        os.makedirs(root_dir + 'test/' + cls)\n",
    "\n",
    "        # get pathname of cls\n",
    "        src = root_dir + cls\n",
    "\n",
    "        # split the filenames into chosen training and testing ratio\n",
    "        allFileNames = os.listdir(src)\n",
    "        np.random.shuffle(allFileNames)\n",
    "        train_FileNames, test_FileNames = np.split(np.array(allFileNames),\n",
    "                                                   [int(len(allFileNames) * (1 - test_ratio))])\n",
    "\n",
    "        # copy images into new train folder for cls subfolder\n",
    "        for name in train_FileNames:\n",
    "            shutil.copy(root_dir + cls + '/' + name, root_dir + 'train/' + cls)\n",
    "\n",
    "        # copy images into new test folder for cls subfolder\n",
    "        for name in test_FileNames:\n",
    "            shutil.copy(root_dir + cls + '/' + name, root_dir + 'test/' + cls)\n",
    "    return None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classes_dir = ['MSIMUT_JPEG', 'MSS_JPEG']\n",
    "test_ratio = 0.3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# root_dir: filepath of coad_msi_mss with '/' at the back\n",
    "root_dir = '/Users/vionnietan/Desktop/trial_dataset/coad_msi_mss/'\n",
    "# root_dir = '/Users/elainealverina/Desktop/trial_dataset/'\n",
    "\n",
    "#root_dir = '/Users/elainealverina/Documents/GitHub/FIT3164-LocalRepo/FIT3164/cancer dataset/coad_msi_mss/'\n",
    "#root_dir = '/Users/vionnietan/Desktop/cancer dataset/coad_msi_mss/'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img_train_test_split(root_dir, classes_dir, test_ratio)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Augmentation and Normalization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_transformation_train = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "data_transformation_test = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "root_dir_train = '/Users/vionnietan/Desktop/trial_dataset/coad_msi_mss/train'\n",
    "#root_dir_train = '/Users/elainealverina/Documents/GitHub/FIT3164-LocalRepo/FIT3164/cancer dataset/coad_msi_mss/train'\n",
    "#root_dir_train = '/Users/elainealverina/Desktop/trial_dataset/train'\n",
    "\n",
    "root_dir_test = '/Users/vionnietan/Desktop/trial_dataset/coad_msi_mss/test'\n",
    "#root_dir_test = '/Users/elainealverina/Documents/GitHub/FIT3164-LocalRepo/FIT3164/cancer dataset/coad_msi_mss/test'\n",
    "#root_dir_test = '/Users/elainealverina/Desktop/trial_dataset/test'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_image_dataset = datasets.ImageFolder(root = root_dir_train, transform=data_transformation_train)\n",
    "test_image_dataset = datasets.ImageFolder(root = root_dir_test, transform=data_transformation_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare DataLoader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainloader = DataLoader(train_image_dataset, batch_size=128, shuffle=True)\n",
    "testloader = DataLoader(test_image_dataset, batch_size=128, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Visualization (Display some images)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class_names = trainloader.dataset.classes\n",
    "\n",
    "def show_images(images, labels, preds):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    for i, image in enumerate(images):\n",
    "        if i < 5:\n",
    "            plt.subplot(1, 6, i+1, xticks=[], yticks=[])\n",
    "            \n",
    "            # Convert to from tensor to numpy\n",
    "            # Take its transpose because\n",
    "            # In ResNet implementation, the format for input is n_channels * n_height * n_width (!and not n_height * n_width * n_channels)\n",
    "            image = image.numpy().transpose((1, 2, 0))  # Set axes\n",
    "            \n",
    "            # Images were normalised earlier.\n",
    "            # To show the image denormalise the images\n",
    "            mean = np.array([0.485, 0.456, 0.406])\n",
    "            std = np.array([0.229, 0.224, 0.225])\n",
    "            \n",
    "            image = image*std + mean\n",
    "            image = np.clip(image, 0.,1.)\n",
    "            plt.imshow(image)\n",
    "            \n",
    "            colour = 'green' if preds[i] == labels[i] else 'red'\n",
    "            \n",
    "            plt.xlabel(f'{class_names[int(labels[i].numpy())]}')\n",
    "            plt.ylabel(f'{class_names[int(preds[i].numpy())]}', color=colour)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# Since predictions are not available for training data yet\n",
    "# Labels are used in place of predictions\n",
    "show_images(images, labels, labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Show Images of Testing Data\n",
    "images_test, labels_test = next(iter(testloader))\n",
    "show_images(images_test,labels_test, labels_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating Model - Load resnet18"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Switch to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "#print(resnet18)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Classifier architecture to put on top of resnet18\n",
    "resnet18.fc = torch.nn.Linear(in_features=512, out_features=3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Using Adam Optimizer\n",
    "optimizer = torch.optim.Adam(resnet18.parameters(), lr=0.0001)\n",
    "resnet18.to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def show_preds():\n",
    "    resnet18.eval()    # set to evaluation mode\n",
    "    images, labels = next(iter(testloader))\n",
    "    outputs = resnet18(images)\n",
    "    _ , preds = torch.max(outputs, 1)\n",
    "    show_images(images, labels, preds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "show_preds()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train(epochs):\n",
    "    print('Started training...')\n",
    "    for e in range(0, epochs):\n",
    "        print('='*20)\n",
    "        print(f'Starting epoch {e+1}/{epochs}')\n",
    "        print('='*20)\n",
    "        \n",
    "        train_loss = 0\n",
    "        \n",
    "        resnet18.train()   # set to training mode\n",
    "        \n",
    "        for train_step, (images, labels) in enumerate(trainloader):\n",
    "            \n",
    "            # Refresh optimizer and set gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            outputs = resnet18(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            if train_step % 20 == 0:\n",
    "                print('\\nEvaluating at step:', train_step)\n",
    "                acc = 0.\n",
    "                val_loss = 0.\n",
    "                resnet18.eval()\n",
    "                \n",
    "                for val_step, (images, labels) in enumerate(testloader):\n",
    "                    outputs = resnet18(images)\n",
    "                    loss = loss_fn(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    _ , preds = torch.max(outputs, 1)\n",
    "                    acc += sum((preds == labels).numpy())\n",
    "                    \n",
    "                val_loss /= (val_step + 1)\n",
    "                acc /= len(test_image_dataset)\n",
    "                print(f'Val loss = {val_loss:.4f}, Accuracy = {acc:.4f}')\n",
    "                # show_preds()\n",
    "                \n",
    "                resnet18.train()\n",
    "        \n",
    "        train_loss /= (train_step+1)\n",
    "        print(f'\\nTraining loss = {train_loss:.4f}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train(epochs=10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epochs = 5\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 1\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        logps = resnet18.forward(inputs)\n",
    "        loss = loss_fn(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            resnet18.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = resnet18.forward(inputs)\n",
    "                    batch_loss = loss_fn(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader))                    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            resnet18.train()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_epochs = 10\n",
    "print_every = 1\n",
    "valid_loss_min = np.Inf\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "total_step = len(trainloader)\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total=0\n",
    "    print(f'Epoch {epoch}\\n')\n",
    "    for batch_idx, (data_, target_) in enumerate(trainloader):\n",
    "        data_, target_ = data_.to(device), target_.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = resnet18(data_)\n",
    "        loss = loss_fn(outputs, target_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _,pred = torch.max(outputs, dim=1)\n",
    "        correct += torch.sum(pred==target_).item()\n",
    "        total += target_.size(0)\n",
    "        if (batch_idx) % 20 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n",
    "    train_acc.append(100 * correct / total)\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    print(f'\\ntrain-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
    "    batch_loss = 0\n",
    "    total_t=0\n",
    "    correct_t=0\n",
    "    with torch.no_grad():\n",
    "        resnet18.eval()\n",
    "        for data_t, target_t in (testloader):\n",
    "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "            outputs_t = resnet18(data_t)\n",
    "            loss_t = loss_fn(outputs_t, target_t)\n",
    "            batch_loss += loss_t.item()\n",
    "            _,pred_t = torch.max(outputs_t, dim=1)\n",
    "            correct_t += torch.sum(pred_t==target_t).item()\n",
    "            total_t += target_t.size(0)\n",
    "        val_acc.append(100 * correct_t/total_t)\n",
    "        val_loss.append(batch_loss/len(testloader))\n",
    "        network_learned = batch_loss < valid_loss_min\n",
    "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\n')\n",
    "\n",
    "        \n",
    "        if network_learned:\n",
    "            valid_loss_min = batch_loss\n",
    "            torch.save(resnet18.state_dict(), 'resnet.pt')\n",
    "            print('Improvement-Detected, save-model')\n",
    "    resnet18.train()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('--' * 5)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.save(resnet18, '/Users/vionnietan/Desktop/resnet18.pth')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}